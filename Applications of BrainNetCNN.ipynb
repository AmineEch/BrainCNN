{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of BrainNetCNN \n",
    "## Summary :\n",
    "This notebook uses the brainnetCNN described [here](https://github.com/AmineEch/BrainCNN/blob/master/BrainNetCNN.ipynb) to execute various predictions on data collected from nilearn database, than we compare the performance of BrainNetCNN against other methods (such as svms) known to preform desently on these sets of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.interactive(False)\n",
    "from scipy.stats import pearsonr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras import optimizers, callbacks, regularizers, initializers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from E2E_conv import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from nilearn import datasets\n",
    "from nilearn import input_data\n",
    "from nilearn.connectome import ConnectivityMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching datasets and constructing the training and test data :\n",
    "We compute region signals and extract useful phenotypic informations, We use 'tangent' connectivity kind to construct the connectomes. (for more information click [here](https://nilearn.github.io/auto_examples/03_connectivity/plot_group_level_connectivity.html#sphx-glr-auto-examples-03-connectivity-plot-group-level-connectivity-py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adhd_data = datasets.fetch_adhd(n_subjects=20)\n",
    "msdl_data = datasets.fetch_atlas_msdl()\n",
    "msdl_coords = msdl_data.region_coords\n",
    "\n",
    "masker = input_data.NiftiMapsMasker(\n",
    "    msdl_data.maps, resampling_target=\"data\", t_r=2.5, detrend=True,\n",
    "    low_pass=.1, high_pass=.01, memory='nilearn_cache', memory_level=1)\n",
    "adhd_subjects = []\n",
    "pooled_subjects = []\n",
    "site_names = []\n",
    "adhd_labels = []  # 1 if ADHD, 0 if control\n",
    "for func_file, confound_file, phenotypic in zip(\n",
    "        adhd_data.func, adhd_data.confounds, adhd_data.phenotypic):\n",
    "    time_series = masker.fit_transform(func_file, confounds=confound_file)\n",
    "    pooled_subjects.append(time_series)\n",
    "    is_adhd = phenotypic['adhd']\n",
    "    if is_adhd:\n",
    "        adhd_subjects.append(time_series)\n",
    "\n",
    "    site_names.append(phenotypic['site'])\n",
    "    adhd_labels.append(is_adhd)\n",
    "\n",
    "conn_measure = ConnectivityMeasure(kind=\"tangent\")\n",
    "x_train = conn_measure.fit_transform(pooled_subjects)\n",
    "y_train = np.array(adhd_labels,dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the network archticeture\n",
    "Unlike the BrainNetCNN used to predict cognitive and motor score described [here](https://github.com/AmineEch/BrainCNN/blob/master/BrainNetCNN.ipynb), we opt for a less deeper network architecture considering the limited size of data to prevent overfitting, therefore we use one E2E layer instead of 2, with less units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_shape : (2, 39, 1, 8)\n",
      "data shape : (?, 39, 39, 1)\n",
      "(1, 39, 1, 8)\n",
      "(39, 1, 1, 8)\n",
      "cat1(?, 39, 39, 8)\n",
      "cat2<dtype: 'float32'>\n",
      "First layer output shape :(None, 39, 39, 8)\n",
      "(None, 39, 39, 8)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "e2e_conv_1 (E2E_conv)        (None, 39, 39, 8)         624       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 39, 39, 8)         0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 39, 39, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 39, 1, 32)         10016     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 39, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 90)          112410    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1, 1, 90)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 90)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1, 64)          5824      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 1, 10)          650       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1, 1, 1)           11        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 129,535\n",
      "Trainable params: 129,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "batch_size = 14\n",
    "dropout = 0.5\n",
    "momentum = 0.9\n",
    "lr = 0.001\n",
    "decay = 0.0005\n",
    "\n",
    "reg = regularizers.l2(decay)\n",
    "kernel_init = initializers.he_uniform()\n",
    "\n",
    "# Model architecture\n",
    "\n",
    "model = Sequential()\n",
    "model.add(E2E_conv(2,8,(2,39),kernel_regularizer=reg,input_shape=(39,39,1),input_dtype='float32',data_format=\"channels_last\"))\n",
    "print(\"First layer output shape :\"+str(model.output_shape))\n",
    "model.add(LeakyReLU(alpha=0.33))\n",
    "#print(model.output_shape)\n",
    "print(model.output_shape)\n",
    "model.add(LeakyReLU(alpha=0.33))\n",
    "model.add(Convolution2D(32,(1,39),kernel_regularizer=reg,data_format=\"channels_last\"))\n",
    "model.add(LeakyReLU(alpha=0.33))\n",
    "model.add(Convolution2D(90,(39,1),kernel_regularizer=reg,data_format=\"channels_last\"))\n",
    "model.add(LeakyReLU(alpha=0.33))\n",
    "#print(model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64,kernel_regularizer=reg,kernel_initializer=kernel_init))\n",
    "#print(model.output_shape)\n",
    "model.add(LeakyReLU(alpha=0.33))\n",
    "#print(model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,kernel_regularizer=reg,kernel_initializer=kernel_init))\n",
    "model.add(LeakyReLU(alpha=0.33))\n",
    "#print(model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,kernel_regularizer=reg,kernel_initializer=kernel_init))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "#print(model.output_shape)\n",
    "\n",
    "\n",
    "opt = optimizers.SGD(nesterov=True,lr=lr)\n",
    "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "csv_logger = callbacks.CSVLogger('predict_age.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_train,y_train,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train or predict ? [t/p]p\n",
      "[*] Predicting and printing results for the models trained :\n",
      "Accuracy : 85.71 %\n"
     ]
    }
   ],
   "source": [
    "command = str(raw_input(\"Train or predict ? [t/p]\"))\n",
    "if command == \"t\":\n",
    "    print(\"Training the model ...\")\n",
    "    history=model.fit(x_train,y_train,batch_size=1,nb_epoch=1000,verbose=1,callbacks=[csv_logger])\n",
    "    model.save_weights(\"Weights/BrainCNNWeights_categ.h5\")\n",
    "else:\n",
    "    print(\"[*] Predicting and printing results for the models trained :\")\n",
    "    model.load_weights(\"Weights/BrainCNNWeights_categ.h5\")\n",
    "    y_pred = model.predict(x_test)\n",
    "    print('Accuracy : ' + str(\"{0:.2f}\".format(accuracy_score(y_test, y_pred)*100))+\" %\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BrainNetCNN does out preform the svm methode used [here](https://nilearn.github.io/auto_examples/03_connectivity/plot_group_level_connectivity.html#sphx-glr-auto-examples-03-connectivity-plot-group-level-connectivity-py) by a margin of approximatly 10% accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
